{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InRIcxm034Ml"
      },
      "source": [
        "# LiteLLM x IBM [watsonx.ai](https://www.ibm.com/products/watsonx-ai)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xXaiaIB34Mn"
      },
      "source": [
        "## Pre-Requisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "L2gPtwQ834Mn"
      },
      "outputs": [],
      "source": [
        "!pip install litellm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFesvGZn34Mo"
      },
      "source": [
        "## Set watsonx.ai Credentials\n",
        "\n",
        "See [this documentation](https://cloud.ibm.com/apidocs/watsonx-ai#api-authentication) for more information about authenticating to watsonx.ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "S1CXdlx634Mp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import litellm\n",
        "from litellm.llms.watsonx.common_utils import generate_iam_token\n",
        "\n",
        "litellm.set_verbose = False\n",
        "\n",
        "os.environ[\"WATSONX_URL\"] = \"https://us-south.ml.cloud.ibm.com\"\n",
        "os.environ[\"WATSONX_APIKEY\"] = \"<your key>\"\n",
        "os.environ[\"WATSONX_PROJECT_ID\"] = \"<your project id>\"\n",
        "# these can also be passed as arguments to the function\n",
        "\n",
        "# generating an IAM token is optional, but it is recommended to generate it once and use it for all your requests during the session\n",
        "# if not passed to the function, it will be generated automatically for each request\n",
        "iam_token = generate_iam_token(api_key=os.environ[\"WATSONX_APIKEY\"])\n",
        "# you can also set os.environ[\"WATSONX_TOKEN\"] = iam_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Zbppz0N34Mp"
      },
      "source": [
        "## Chat with tools Requests\n",
        "\n",
        "See the following link for a list of supported *tool calling* models available with watsonx.ai:\n",
        "\n",
        "https://www.ibm.com/watsonx/developer/capabilities/tool-calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8v86ogH634Mp",
        "outputId": "1ebc2655-3ff4-48fd-df22-aabbb4413e76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mistral response using tool:\n",
            "ModelResponse(id='chat-b57c8100a28a490492e906262e207312', created=1731492279, model='watsonx/mistralai/mistral-large', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 2, \"b\": 4}', name='add'), id='vzRMhObVv', type='function')], function_call=None))], usage=Usage(completion_tokens=25, prompt_tokens=103, total_tokens=128, completion_tokens_details=None, prompt_tokens_details=None), model_id='mistralai/mistral-large', model_version='2.0.0', created_at='2024-11-13T10:04:40.478Z', system={'warnings': [{'message': 'This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations. By using this model you agree to its terms as identified in the following URL.', 'id': 'disclaimer_warning', 'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx'}, {'message': \"The value of 'max_tokens' for this model was set to value 1024\", 'id': 'unspecified_max_token', 'additional_properties': {'limit': 0, 'new_value': 1024, 'parameter': 'max_tokens', 'value': 0}}]})\n"
          ]
        }
      ],
      "source": [
        "from litellm import completion\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "                \"type\": \"text\",\n",
        "                \"text\": \"What is 2 plus 4?\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"add\",\n",
        "            \"description\": \"Adds the values a and b to get a sum.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"a\": {\n",
        "                        \"description\": \"A number value\",\n",
        "                        \"type\": \"float\"\n",
        "                    },\n",
        "                    \"b\": {\n",
        "                        \"description\": \"A number value\",\n",
        "                        \"type\": \"float\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\n",
        "                    \"a\",\n",
        "                    \"b\"\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "response = completion(\n",
        "        model=\"watsonx/mistralai/mistral-large\",\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        token=iam_token\n",
        ")\n",
        "\n",
        "print(\"Mistral response using tool:\")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}